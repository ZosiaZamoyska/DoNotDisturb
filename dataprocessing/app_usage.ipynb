{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the data from Drive\n",
        "Mount the drive, save each file of AppUsageEventEntity as a separate dataframe for each day."
      ],
      "metadata": {
        "id": "qQL_291pJl1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pT7d3u7aJoCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd2ce95-cd5e-47c9-e005-1e7bab4c5bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/My Drive/CS481_Data Visualization/data\"\n",
        "AUEE_day1 = pd.read_csv(filepath+\"/3001/AppUsageEventEntity-5565824000.csv\")\n",
        "AUEE_day2 = pd.read_csv(filepath+\"/3001/AppUsageEventEntity-5566688000.csv\")\n",
        "AUEE_day3 = pd.read_csv(filepath+\"/3001/AppUsageEventEntity-5567552000.csv\")\n",
        "AUEE_day4 = pd.read_csv(filepath+\"/3001/AppUsageEventEntity-5568416000.csv\")\n",
        "AUEE_day5 = pd.read_csv(filepath+\"/3001/AppUsageEventEntity-5569280000.csv\")\n",
        "AUEE_day6 = pd.read_csv(filepath+\"/3001/AppUsageEventEntity-5570144000.csv\")\n",
        "AUEE_day7 = pd.read_csv(filepath+\"/3001/AppUsageEventEntity-5571008000.csv\")\n",
        "AUEE_days = [AUEE_day1, AUEE_day2, AUEE_day3, AUEE_day4, AUEE_day5, AUEE_day6, AUEE_day7]"
      ],
      "metadata": {
        "id": "_usAq_6YbLH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing for week-in-review and user goal\n",
        "Use only 'MOVE_TO_FOREGROUND' and 'MOVE_TO_BACKGROUND'data, calculate time between those interactions to know how long was an app used. Week-in-review dataset contains list of apps being used sequentially with time of usage and start time. This dataframe is used to create user goal dataframe that contains summarized usage time of each app for each day.\n",
        "Dataframes are exported as csv files."
      ],
      "metadata": {
        "id": "LpH7y7eUzK2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(AUEE_days)):\n",
        "  df = AUEE_days[i].copy()\n",
        "  df = df[df.type.isin(['MOVE_TO_FOREGROUND', 'MOVE_TO_BACKGROUND'])]\n",
        "  entries_list = []\n",
        "  prev = None\n",
        "  idx = 0\n",
        "  for _, item in df.iterrows():\n",
        "    if (idx>0):\n",
        "      if (prev['name'] == item['name']):\n",
        "        new_row = {'timestamp':prev.timestamp, 'time':item.timestamp-prev.timestamp, 'name':item[\"name\"]}\n",
        "        entries_list.append(new_row)\n",
        "    prev = item\n",
        "    idx+=1\n",
        "  df_entries = pd.DataFrame(entries_list)\n",
        "  df_entries['startTime'] = pd.to_datetime(df_entries.timestamp, unit='ms')\n",
        "  df_entries['endTime'] = pd.to_datetime(df_entries.timestamp+df_entries.time, unit='ms')\n",
        "  df_entries['minUsed'] = df_entries.time/60000\n",
        "  df_day = df_entries.groupby('name').sum()\n",
        "  path_save1 = \"/content/drive/My Drive/CS481_Data Visualization/results/review_entries_day\"+str(i+1)\n",
        "  path_save2 = \"/content/drive/My Drive/CS481_Data Visualization/results/review_full_day\"+str(i+1)\n",
        "  df_entries.to_csv(path_save1 + \".csv\")\n",
        "  df_day.to_csv(path_save2 + \".csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGJEPFjkbLKZ",
        "outputId": "b001ef41-ab96-4a0d-fe47-0ed7bd5d6d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-136-65c7788ab9c2>:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_day = df_entries.groupby('name').sum()\n",
            "<ipython-input-136-65c7788ab9c2>:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_day = df_entries.groupby('name').sum()\n",
            "<ipython-input-136-65c7788ab9c2>:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_day = df_entries.groupby('name').sum()\n",
            "<ipython-input-136-65c7788ab9c2>:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_day = df_entries.groupby('name').sum()\n",
            "<ipython-input-136-65c7788ab9c2>:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_day = df_entries.groupby('name').sum()\n",
            "<ipython-input-136-65c7788ab9c2>:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_day = df_entries.groupby('name').sum()\n",
            "<ipython-input-136-65c7788ab9c2>:18: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_day = df_entries.groupby('name').sum()\n"
          ]
        }
      ]
    }
  ]
}